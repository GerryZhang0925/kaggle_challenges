{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "from scipy import stats\n",
    "import lightgbm as lgb\n",
    "#import jpx_tokyo_market_prediction\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import RidgeCV, LassoCV\n",
    "from sklearn.model_selection import cross_val_score, KFold, TimeSeriesSplit, GroupKFold, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "SEED=42\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./train_files/stock_prices.csv\",parse_dates=[\"Date\"])\n",
    "train=train.drop(columns=['RowId','ExpectedDividend','AdjustmentFactor','SupervisionFlag']).dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(feats):\n",
    "    feats[\"return_1month\"] = feats[\"Close\"].pct_change(20)\n",
    "    feats[\"return_2month\"] = feats[\"Close\"].pct_change(40)\n",
    "    feats[\"return_3month\"] = feats[\"Close\"].pct_change(60)\n",
    "    feats[\"volatility_1month\"] = (\n",
    "        np.log(feats[\"Close\"]).diff().rolling(20).std()\n",
    "    )\n",
    "    feats[\"volatility_2month\"] = (\n",
    "        np.log(feats[\"Close\"]).diff().rolling(40).std()\n",
    "    )\n",
    "    feats[\"volatility_3month\"] = (\n",
    "        np.log(feats[\"Close\"]).diff().rolling(60).std()\n",
    "    )\n",
    "    feats[\"MA_gap_1month\"] = feats[\"Close\"] / (\n",
    "        feats[\"Close\"].rolling(20).mean()\n",
    "    )\n",
    "    feats[\"MA_gap_2month\"] = feats[\"Close\"] / (\n",
    "        feats[\"Close\"].rolling(40).mean()\n",
    "    )\n",
    "    feats[\"MA_gap_3month\"] = feats[\"Close\"] / (\n",
    "        feats[\"Close\"].rolling(60).mean()\n",
    "    )\n",
    "    \n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = add_features(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feval_rmse(y_pred, lgb_train):\n",
    "    y_true = lgb_train.get_label()\n",
    "    return 'rmse', mean_squared_error(y_true, y_pred), False\n",
    "\n",
    "def feval_pearsonr(y_pred, lgb_train):\n",
    "    y_true = lgb_train.get_label()\n",
    "    return 'pearsonr', stats.pearsonr(y_true, y_pred)[0], True\n",
    "\n",
    "def calc_spread_return_per_day(df, portfolio_size=200, toprank_weight_ratio=2):\n",
    "    assert df['Rank'].min() == 0\n",
    "    assert df['Rank'].max() == len(df['Rank']) - 1\n",
    "    weights = np.linspace(start=toprank_weight_ratio, stop=1, num=portfolio_size)\n",
    "    purchase = (df.sort_values(by='Rank')['Target'][:portfolio_size] * weights).sum() / weights.mean()\n",
    "    short = (df.sort_values(by='Rank', ascending=False)['Target'][:portfolio_size] * weights).sum() / weights.mean()\n",
    "    return purchase - short\n",
    "\n",
    "def calc_spread_return_sharpe(df: pd.DataFrame, portfolio_size=200, toprank_weight_ratio=2):\n",
    "    buf = df.groupby('Date').apply(calc_spread_return_per_day, portfolio_size, toprank_weight_ratio)\n",
    "    sharpe_ratio = buf.mean() / buf.std()\n",
    "    return sharpe_ratio#, buf\n",
    "\n",
    "def add_rank(df):\n",
    "    df[\"Rank\"] = df.groupby(\"Date\")[\"Target\"].rank(ascending=False, method=\"first\") - 1 \n",
    "    df[\"Rank\"] = df[\"Rank\"].astype(\"int\")\n",
    "    return df\n",
    "\n",
    "def fill_nan_inf(df):\n",
    "    df = df.fillna(0)\n",
    "    df = df.replace([np.inf, -np.inf], 0)\n",
    "    return df\n",
    "\n",
    "def feval_rmse(y_pred, lgb_train):\n",
    "    y_true = lgb_train.get_label()\n",
    "    return 'rmse', mean_squared_error(y_true, y_pred), False\n",
    "\n",
    "def feval_pearsonr(y_pred, lgb_train):\n",
    "    y_true = lgb_train.get_label()\n",
    "    return 'pearsonr', stats.pearsonr(y_true, y_pred)[0], True\n",
    "\n",
    "def calc_spread_return_per_day(df, portfolio_size=200, toprank_weight_ratio=2):\n",
    "    assert df['Rank'].min() == 0\n",
    "    assert df['Rank'].max() == len(df['Rank']) - 1\n",
    "    weights = np.linspace(start=toprank_weight_ratio, stop=1, num=portfolio_size)\n",
    "    purchase = (df.sort_values(by='Rank')['Target'][:portfolio_size] * weights).sum() / weights.mean()\n",
    "    short = (df.sort_values(by='Rank', ascending=False)['Target'][:portfolio_size] * weights).sum() / weights.mean()\n",
    "    return purchase - short\n",
    "\n",
    "def calc_spread_return_sharpe(df: pd.DataFrame, portfolio_size=200, toprank_weight_ratio=2):\n",
    "    buf = df.groupby('Date').apply(calc_spread_return_per_day, portfolio_size, toprank_weight_ratio)\n",
    "    sharpe_ratio = buf.mean() / buf.std()\n",
    "    return sharpe_ratio#, buf\n",
    "\n",
    "def add_rank(df):\n",
    "    df[\"Rank\"] = df.groupby(\"Date\")[\"Target\"].rank(ascending=False, method=\"first\") - 1 \n",
    "    df[\"Rank\"] = df[\"Rank\"].astype(\"int\")\n",
    "    return df\n",
    "\n",
    "def fill_nan_inf(df):\n",
    "    df = df.fillna(0)\n",
    "    df = df.replace([np.inf, -np.inf], 0)\n",
    "    return df\n",
    "\n",
    "def check_score(df,preds,Securities_filter=[]):\n",
    "    tmp_preds=df[['Date','SecuritiesCode']].copy()\n",
    "    tmp_preds['Target']=preds\n",
    "    \n",
    "    #Rank Filter. Calculate median for this date and assign this value to the list of Securities to filter.\n",
    "    tmp_preds['target_mean']=tmp_preds.groupby(\"Date\")[\"Target\"].transform('median')\n",
    "    tmp_preds.loc[tmp_preds['SecuritiesCode'].isin(Securities_filter),'Target']=tmp_preds['target_mean']\n",
    "    \n",
    "    tmp_preds = add_rank(tmp_preds)\n",
    "    df['Rank']=tmp_preds['Rank']\n",
    "    score=round(calc_spread_return_sharpe(df, portfolio_size= 200, toprank_weight_ratio= 2),5)\n",
    "    score_mean=round(df.groupby('Date').apply(calc_spread_return_per_day, 200, 2).mean(),5)\n",
    "    score_std=round(df.groupby('Date').apply(calc_spread_return_per_day, 200, 2).std(),5)\n",
    "    print(f'Competition_Score:{score}, rank_score_mean:{score_mean}, rank_score_std:{score_std}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_spred_h=list((train.groupby('SecuritiesCode')['Target'].max()-train.groupby('SecuritiesCode')['Target'].min()).sort_values()[:1000].index)\n",
    "list_spred_l=list((train.groupby('SecuritiesCode')['Target'].max()-train.groupby('SecuritiesCode')['Target'].min()).sort_values()[1000:].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's pearsonr: 0.0564282\tvalid_1's pearsonr: 0.0108009\n",
      "[200]\ttraining's pearsonr: 0.0680563\tvalid_1's pearsonr: 0.0134107\n",
      "[300]\ttraining's pearsonr: 0.0761529\tvalid_1's pearsonr: 0.0142165\n",
      "[400]\ttraining's pearsonr: 0.082453\tvalid_1's pearsonr: 0.0146069\n",
      "[500]\ttraining's pearsonr: 0.0883774\tvalid_1's pearsonr: 0.0147149\n",
      "[600]\ttraining's pearsonr: 0.0938508\tvalid_1's pearsonr: 0.0148599\n",
      "[700]\ttraining's pearsonr: 0.0986576\tvalid_1's pearsonr: 0.014839\n",
      "[800]\ttraining's pearsonr: 0.103034\tvalid_1's pearsonr: 0.014711\n",
      "[900]\ttraining's pearsonr: 0.106989\tvalid_1's pearsonr: 0.0146882\n",
      "Early stopping, best iteration is:\n",
      "[606]\ttraining's pearsonr: 0.0942029\tvalid_1's pearsonr: 0.0148712\n"
     ]
    }
   ],
   "source": [
    "# Training just with Securities with hight target_spread and validated with Securities with low target_spread.\n",
    "\n",
    "features =['High','Low','Open','Close','Volume', 'return_1month', 'return_2month', 'return_3month', 'volatility_1month', 'volatility_2month', 'volatility_3month',\n",
    "       'MA_gap_1month', 'MA_gap_2month', 'MA_gap_3month']\n",
    "# features =['High','Low','Open','Close','Volume',]\n",
    "train=fill_nan_inf(train)\n",
    "\n",
    "params_lgb = {'learning_rate': 0.005,'metric':'None','objective': 'regression','boosting': 'gbdt','verbosity': 0,'n_jobs': -1,'force_col_wise':True}  \n",
    "\n",
    "tr_dataset = lgb.Dataset(train[train['SecuritiesCode'].isin(list_spred_h)][features],train[train['SecuritiesCode'].isin(list_spred_h)][\"Target\"],feature_name = features )\n",
    "vl_dataset = lgb.Dataset(train[train['SecuritiesCode'].isin(list_spred_l)][features], train[train['SecuritiesCode'].isin(list_spred_l)][\"Target\"],feature_name = features)\n",
    "\n",
    "model = lgb.train(params = params_lgb, \n",
    "                train_set = tr_dataset, \n",
    "                valid_sets = [tr_dataset, vl_dataset], \n",
    "                num_boost_round = 3000, \n",
    "                feval=feval_pearsonr,\n",
    "                callbacks=[ lgb.early_stopping(stopping_rounds=300, verbose=True), lgb.log_evaluation(period=100)])    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.023902313714663583\n",
      "Competition_Score:0.25684, rank_score_mean:0.18588, rank_score_std:0.72371\n",
      "Competition_Score:0.22799, rank_score_mean:0.18293, rank_score_std:0.80235\n",
      "Competition_Score:0.194, rank_score_mean:0.10493, rank_score_std:0.54088\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv(\"./supplemental_files/stock_prices.csv\",parse_dates=[\"Date\"])\n",
    "test=test.drop(columns=['RowId','ExpectedDividend','AdjustmentFactor','SupervisionFlag'])\n",
    "test = add_features(test)\n",
    "test=fill_nan_inf(test)\n",
    "preds=model.predict(test[features])\n",
    "print(math.sqrt(mean_squared_error(preds,test.Target)))\n",
    "\n",
    "check_score(test,preds)\n",
    "check_score(test,preds,list_spred_h)\n",
    "check_score(test,preds,list_spred_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
